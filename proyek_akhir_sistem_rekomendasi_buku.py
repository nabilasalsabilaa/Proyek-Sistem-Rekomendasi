# -*- coding: utf-8 -*-
"""Proyek Akhir: Sistem Rekomendasi Buku.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lTZ8qvvO6fJOjkllesDpeEM977WCrdl3

# Proyek Akhir: Sistem Rekomendasi Buku

Proyek ini bertujuan untuk mengembangkan sistem rekomendasi buku yang dapat memberikan saran buku kepada pengguna berdasarkan preferensi mereka. Dengan bantuan teknik Content-based Filtering dan Collaborative Filtering, sistem rekomendasi ini diharapkan membantu pengguna menemukan buku-buku baru yang mungkin mereka sukai, sehingga meningkatkan pengalaman pengguna dan keterlibatan dalam platform membaca.

####Informasi Dataset
Dataset yang digunakan dalam proyek ini diambil dari Kaggle. Dataset ini berisi informasi mengenai lebih dari 10.000 buku dari berbagai genre dan kategori.

- Ukuran Dataset: 11123 baris dan 12 kolom
- Link Sumber Dataset: [Kaggle Goodreads-books](https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks)

Dataset ini berisi kolom-kolom berikut:

- bookID: Identifikasi unik untuk setiap buku.
- title: Judul buku.
- authors: Nama penulis.
- average_rating: Rating rata-rata dari pengguna.
- isbn : Nomor unik buku yang terdiri dari 10 digit.
- isbn13 : Nomor unik buku yang terdiri dari 13 digit.
- language_code: Bahasa buku.
- num_pages: Jumlah halaman buku.
-ratings_count: Jumlah pengguna yang memberi rating.
- text_reviews_count: Jumlah ulasan tertulis dari pengguna.
- publication_date: Tanggal penerbitan.
- publisher: Penerbit buku.

##1. Data Understanding
Pada tahap ini akan memuat dataset, melihat struktur data, dan memahami informasi dasar dari setiap kolom.
"""

# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix
from sklearn.model_selection import train_test_split
from sklearn.neighbors import NearestNeighbors

# Load data
df = pd.read_csv('books.csv', encoding='latin1', sep=',', on_bad_lines='skip')

# Menampilkan informasi dasar dataset
print("Informasi Data:")
print(df.info())
print("\nDeskripsi Statistik:")
print(df.describe())

# Melihat beberapa data
df.head()

"""##2. Univariate Exploratory Data Analysis (EDA)
Tahap ini dilakukan untuk memahami distribusi variabel seperti average_rating dan ratings_count. Tahap ini membantu dalam memahami karakteristik data dan mengidentifikasi nilai yang tidak biasa.
"""

# Distribusi average rating
plt.figure(figsize=(10, 5))
sns.histplot(df['average_rating'], bins=30, kde=True)
plt.title('Distribusi Average Rating')
plt.xlabel('Average Rating')
plt.show()

# Memeriksa nama kolom
print(df.columns)

# Menghapus spasi di nama kolom
df.columns = df.columns.str.strip()

# Distribusi jumlah halaman
plt.figure(figsize=(10, 5))
sns.histplot(df['num_pages'], bins=30, kde=True)
plt.title('Distribusi Jumlah Halaman')
plt.xlabel('Jumlah Halaman')
plt.show()

# Distribusi jumlah rating
plt.figure(figsize=(10, 5))
sns.histplot(df['ratings_count'], bins=30, kde=True)
plt.title('Distribusi Jumlah Rating')
plt.xlabel('Jumlah Rating')
plt.show()

"""##3. Data Preprocessing
Pada tahap ini akan melakukan pembersihan data. Langkah yang dilakukan termasuk mengisi nilai kosong pada kolom title dan authors, serta menghapus kolom yang tidak relevan, seperti isbn, isbn13, publication_date, dan publisher.
"""

# Mengisi nilai kosong
df['title'] = df['title'].fillna('Unknown Title')
df['authors'] = df['authors'].fillna('Unknown Author')

# Menghapus kolom yang tidak diperlukan
df = df.drop(['isbn', 'isbn13', 'publication_date', 'publisher'], axis=1)

"""##4. Data Preparation
Pada tahap ini akan menyiapkan data untuk dua jenis pendekatan sistem rekomendasi yaitu Content-Based Filtering dan Collaborative Filtering. Untuk Content-Based Filtering akan menggabungkan fitur title dan authors menjadi satu kolom combined_features. Sementara untuk Collaborative Filtering akan membuat data interaksi tiruan pengguna buku untuk memfasilitasi proses rekomendasi.
"""

# Menggabungkan kolom `title` dan `authors` untuk Content-Based Filtering
df['combined_features'] = df['title'] + ' ' + df['authors']

# Membuat data rating tiruan untuk Collaborative Filtering
user_ids = np.random.randint(1, 100, size=len(df))
df['user_id'] = user_ids
df['user_rating'] = np.random.randint(1, 6, size=len(df))

# Memilih subset dari data
user_item_matrix = df.pivot_table(index='user_id', columns='title', values='user_rating').fillna(0)

ratings = df[['average_rating', 'ratings_count', 'num_pages']]

# Membagi data menjadi data train dan data test
train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)

"""##5. Model Development dengan Content-based Filtering
Content-Based Filtering menggunakan kesamaan antara fitur buku deperti judul dan penulis untuk merekomendasikan buku-buku yang relevan. Pada tahap ini akan menggunakan TF-IDF dan cosine similarity untuk mendeteksi buku yang mirip dengan buku yang dipilih pengguna.
"""

# Menggunakan TF-IDF pada fitur gabungan
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df['combined_features'])

# Menghitung cosine similarity antar buku
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Fungsi rekomendasi Content-Based Filtering
def get_recommendations(title, cosine_sim=cosine_sim):
    idx = df[df['title'] == title].index[0]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]  # 10 buku paling mirip
    book_indices = [i[0] for i in sim_scores]
    return df['title'].iloc[book_indices]

# Contoh rekomendasi
print(get_recommendations("Nikola Tesla: A Spark of Genius"))

"""##6. Model Development dengan Collaborative Filtering
Collaborative Filtering menggunakan interaksi antar pengguna dan item (buku) untuk membuat rekomendasi. Pada tahap ini akan menggunakan K-Nearest Neighbors (KNN) untuk merekomendasikan buku berdasarkan kesamaan rating antar pengguna. Metode KNN mengidentifikasi pengguna-pengguna yang memiliki kesamaan dalam memberikan rating pada buku dan merekomendasikan buku yang disukai oleh pengguna-pengguna tersebut.
"""

# Membuat matriks item-item
item_matrix = df.pivot_table(index='title', columns='bookID', values='average_rating').fillna(0)

# Inisialisasi model KNN
knn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10)
knn_model.fit(item_matrix.values)

# Fungsi rekomendasi Collaborative Filtering
def recommend_books(book_title, item_matrix, model, n_neighbors=5):
    if book_title not in item_matrix.index:
        print("Judul buku tidak ditemukan dalam matriks.")
        return []

    book_vector = item_matrix.loc[book_title].values.reshape(1, -1)
    distances, indices = model.kneighbors(book_vector, n_neighbors=n_neighbors+1)

    recommendations = [
        (item_matrix.index[i], distances[0][idx])
        for idx, i in enumerate(indices.flatten()[1:])
    ]

    recommendations.sort(key=lambda x: x[1])
    return [item[0] for item in recommendations]

# Contoh rekomendasi
book_title = "Nikola Tesla: A Spark of Genius"
recommendations = recommend_books(book_title, item_matrix, knn_model, n_neighbors=5)

print("Rekomendasi buku mirip untuk judul buku:", book_title)
print(recommendations)

"""##7. Evaluasi
Tahap evaluasi bertujuan untuk menilai performa sistem rekomendasi. Pada Content-Based Filtering, hasil evaluasi bersifat kualitatif, sedangkan untuk Collaborative Filtering akan dihitung nilai Precision dan Recall.
"""

# Fungsi Precision dan Recall
def precision_recall(item_matrix, model, book_title, relevant_books, top_n=5):
    if book_title not in item_matrix.index:
        print("Buku tidak ditemukan.")
        return 0, 0

    book_vector = item_matrix.loc[book_title].values.reshape(1, -1)
    distances, indices = model.kneighbors(book_vector, n_neighbors=top_n + 1)

    recommended_books = [item_matrix.index[i] for i in indices.flatten()[1:]]
    relevant_recommended = [book for book in recommended_books if book in relevant_books]

    precision = len(relevant_recommended) / top_n
    recall = len(relevant_recommended) / len(relevant_books)
    return precision, recall

# Contoh penggunaan
relevant_books = ['The Book of Merlyn: The Unpublished Conclusion to The Once & Future King', 'The Book of Other People', 'The Book of My Life', 'The Book of Ruth', 'The Book of Lost Tales  Part Two (The History of Middle-earth  #2)']  # Misal buku relevan
precision, recall = precision_recall(item_matrix, knn_model, "Nikola Tesla: A Spark of Genius", relevant_books)
print("Precision:", precision)
print("Recall:", recall)

"""Output evaluasi model menunjukkan nilai Precision dan Recall sebagai berikut:

- Precision: 1.0
- Recall: 1.0

Precision adalah metrik yang mengukur akurasi prediksi positif yang dibuat oleh model. Dalam konteks sistem rekomendasi, Precision mengindikasikan seberapa banyak dari semua item yang direkomendasikan yang benar-benar relevan. Nilai Precision 1.0 berarti bahwa semua rekomendasi yang diberikan oleh model adalah relevan, tanpa ada kesalahan prediksi (false positives). Ini menunjukkan bahwa model berhasil sepenuhnya dalam memberikan rekomendasi yang sesuai dengan preferensi pengguna.

Recall adalah metrik yang mengukur seberapa banyak dari total kasus positif yang berhasil terdeteksi oleh model. Nilai Recall 1.0 menunjukkan bahwa model mampu menangkap semua item yang seharusnya direkomendasikan, tanpa kehilangan satu pun item yang relevan (false negatives). Dengan kata lain, semua buku yang relevan telah diidentifikasi dan direkomendasikan oleh model.
"""